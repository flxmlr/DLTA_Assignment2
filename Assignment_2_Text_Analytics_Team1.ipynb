{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team information\n",
    "\n",
    "|Team-number :| 1|\n",
    "|:----:|:----:|\n",
    "\n",
    "\n",
    "|Name|    E-Mail        |matriculation-nr.|\n",
    "|:----:|:----:|:----:|\n",
    "|Tamara Scherer| schere21@ads.uni-passau.de|104218|\n",
    "|Felix Müller| muell518@ads.uni-passau.de|104227|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from label_studio_sdk import Client\n",
    "#from label_studio_sdk import project\n",
    "#from label_studio_sdk import project\n",
    "#import pandas as pd\n",
    "#LABEL_STUDIO_URL = 'http://132.231.59.226:8080' #this address needs to be the same as the address the label-studio is hosted on.\n",
    "#API_KEY = '1655a8922f821195356a17a3224c0532b091c61d' #please add your personal API_Key here to get your API_Key follow the Pictures below\n",
    "\n",
    "#ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "#ls.check_connection()\n",
    "#pro = project.Project.get_from_id(ls,\"1\")\n",
    "#tasks = project.Project.get_labeled_tasks(pro)\n",
    "#tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labeled data\n",
    "import pickle\n",
    "with open(\"Files/tasks3\", 'rb') as f:\n",
    "    tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[QID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_2_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, I think that as it relates to the one, I t...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>One of the areas obviously which has been a st...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_1_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_2_positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_3_no_blame]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my ...   \n",
       "1       Good afternoon and thanks a lot for taking my...   \n",
       "2      Good afternoon and thanks a lot for taking my ...   \n",
       "3      Good afternoon and thanks a lot for taking my ...   \n",
       "4      No, I think that as it relates to the one, I t...   \n",
       "...                                                  ...   \n",
       "11289  One of the areas obviously which has been a st...   \n",
       "11290  Well, let's start with the first part of your ...   \n",
       "11291  Well, let's start with the first part of your ...   \n",
       "11292  Well, let's start with the first part of your ...   \n",
       "11293  Well, let's start with the first part of your ...   \n",
       "\n",
       "                               Label  \n",
       "0                            [QID_1]  \n",
       "1      [Question_1_Company_specific]  \n",
       "2              [Question_2_specific]  \n",
       "3               [Question_3_neutral]  \n",
       "4                            [AID_1]  \n",
       "...                              ...  \n",
       "11289           [Question_3_neutral]  \n",
       "11290                        [AID_1]  \n",
       "11291            [Answer_1_specific]  \n",
       "11292            [Answer_2_positive]  \n",
       "11293            [Answer_3_no_blame]  \n",
       "\n",
       "[11294 rows x 2 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the necessary texts with the corresponding label\n",
    "df = pd.DataFrame(columns = ['Text', 'Label',])\n",
    "\n",
    "for i in range(len(tasks)): \n",
    "    for j in range(len(tasks[i]['annotations'][0]['result'])): \n",
    "        df = df.append({\n",
    "            'Text' : tasks[i]['annotations'][0]['result'][j]['value']['text'],\n",
    "            'Label' : tasks[i]['annotations'][0]['result'][j]['value']['labels']\n",
    "                        }, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[QID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_2_specific]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, I think that as it relates to the one, I t...</td>\n",
       "      <td>[AID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>One of the areas obviously which has been a st...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[AID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_1_specific]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_2_positive]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_3_no_blame]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my ...   \n",
       "1       Good afternoon and thanks a lot for taking my...   \n",
       "2      Good afternoon and thanks a lot for taking my ...   \n",
       "3      Good afternoon and thanks a lot for taking my ...   \n",
       "4      No, I think that as it relates to the one, I t...   \n",
       "...                                                  ...   \n",
       "11289  One of the areas obviously which has been a st...   \n",
       "11290  Well, let's start with the first part of your ...   \n",
       "11291  Well, let's start with the first part of your ...   \n",
       "11292  Well, let's start with the first part of your ...   \n",
       "11293  Well, let's start with the first part of your ...   \n",
       "\n",
       "                               Label LabelNumber  \n",
       "0                            [QID_1]           0  \n",
       "1      [Question_1_Company_specific]           1  \n",
       "2              [Question_2_specific]           3  \n",
       "3               [Question_3_neutral]           7  \n",
       "4                            [AID_1]           0  \n",
       "...                              ...         ...  \n",
       "11289           [Question_3_neutral]           7  \n",
       "11290                        [AID_1]           0  \n",
       "11291            [Answer_1_specific]           8  \n",
       "11292            [Answer_2_positive]          10  \n",
       "11293            [Answer_3_no_blame]          13  \n",
       "\n",
       "[11294 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign a unique number to each label\n",
    "def categorise(row):  \n",
    "    if row['Label'] == ['Question_1_Company_specific']:\n",
    "        return '1'\n",
    "    elif row['Label'] == ['Question_1_Market_related']:\n",
    "        return '2'\n",
    "    elif row['Label'] == ['Question_2_specific']:\n",
    "        return '3'\n",
    "    elif row['Label'] == ['Question_2_open']:\n",
    "        return '4'\n",
    "    elif row['Label'] == ['Question_3_attack']:\n",
    "        return '5'\n",
    "    elif row['Label'] == ['Question_3_support']:\n",
    "        return '6'\n",
    "    elif row['Label'] == ['Question_3_neutral']:\n",
    "        return '7'\n",
    "    elif row['Label'] == ['Answer_1_specific']:\n",
    "        return '8'\n",
    "    elif row['Label'] == ['Answer_1_avoid_excuse']:\n",
    "        return '9'\n",
    "    elif row['Label'] == ['Answer_2_positive']:\n",
    "        return '10'\n",
    "    elif row['Label'] == ['Answer_2_negative']:\n",
    "        return '11'\n",
    "    elif row['Label'] == ['Answer_3_blame']:\n",
    "        return '12'\n",
    "    elif row['Label'] == ['Answer_3_no_blame']:\n",
    "        return '13'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n",
    "    \n",
    "# call function and write results in a new column of the dataframe\n",
    "df['LabelNumber'] = df.apply(lambda row: categorise(row), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter one ID stage (e.g. Question_1_XX)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label LabelNumber  \n",
       "0     [Question_1_Company_specific]           1  \n",
       "1     [Question_1_Company_specific]           1  \n",
       "2       [Question_1_Market_related]           2  \n",
       "3     [Question_1_Company_specific]           1  \n",
       "4     [Question_1_Company_specific]           1  \n",
       "...                             ...         ...  \n",
       "1304  [Question_1_Company_specific]           1  \n",
       "1305  [Question_1_Company_specific]           1  \n",
       "1306  [Question_1_Company_specific]           1  \n",
       "1307  [Question_1_Company_specific]           1  \n",
       "1308  [Question_1_Company_specific]           1  \n",
       "\n",
       "[1309 rows x 3 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idStage = ['1', '2']\n",
    "df = df[df['LabelNumber'].isin(idStage)]\n",
    "\n",
    "# set new index\n",
    "df = df.reset_index()\n",
    "# delete old indices\n",
    "df.pop('index')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# necessary imports for preprocessing steps\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# import a stemmer for english words\n",
    "snowStem = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "# import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# import for tokenization\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# import for lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>good afternoon thanks lot taking question so r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay thats helpful growth china surpass expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "      <td>hi richard so gross margin looked pretty solid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>coreoncore pretty normal well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay followup ebit dollar growth looked like c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi mark pat thank much taking question could t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>yes im wondering could talk little bit custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi thank you congrats quarter followup toms qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>thanks squeezing guys question you john know g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>one areas obviously strong growth driver team ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label LabelNumber  \\\n",
       "0     [Question_1_Company_specific]           1   \n",
       "1     [Question_1_Company_specific]           1   \n",
       "2       [Question_1_Market_related]           2   \n",
       "3     [Question_1_Company_specific]           1   \n",
       "4     [Question_1_Company_specific]           1   \n",
       "...                             ...         ...   \n",
       "1304  [Question_1_Company_specific]           1   \n",
       "1305  [Question_1_Company_specific]           1   \n",
       "1306  [Question_1_Company_specific]           1   \n",
       "1307  [Question_1_Company_specific]           1   \n",
       "1308  [Question_1_Company_specific]           1   \n",
       "\n",
       "                                              CleanText  \n",
       "0     good afternoon thanks lot taking question so r...  \n",
       "1     okay thats helpful growth china surpass expect...  \n",
       "2     hi richard so gross margin looked pretty solid...  \n",
       "3                         coreoncore pretty normal well  \n",
       "4     okay followup ebit dollar growth looked like c...  \n",
       "...                                                 ...  \n",
       "1304  hi mark pat thank much taking question could t...  \n",
       "1305  yes im wondering could talk little bit custome...  \n",
       "1306  hi thank you congrats quarter followup toms qu...  \n",
       "1307  thanks squeezing guys question you john know g...  \n",
       "1308  one areas obviously strong growth driver team ...  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that includes all preprocessing steps\n",
    "\n",
    "def do_preprocessing(text_to_clean, remove_stopwords = True, stemming = True):\n",
    "    # remove numbers \n",
    "    text_to_clean = re.sub(r'\\d+', '', text_to_clean)\n",
    "    # remove leading and ending white spaces\n",
    "    text_to_clean = text_to_clean.strip()\n",
    "    # transform text to lower case\n",
    "    text_to_clean = text_to_clean.lower()\n",
    "\n",
    "    if stemming:\n",
    "      # stemming\n",
    "      text_to_clean = snowStem.stem(text_to_clean)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        # remove stop words\n",
    "        text_to_clean = ' '.join([w for w in text_to_clean.split() if not(w in en_stopwords)])\n",
    "\n",
    "    # remove punctuation\n",
    "    text_to_clean = text_to_clean.translate(str.maketrans('','', string.punctuation))\n",
    "    \n",
    "    return text_to_clean\n",
    "\n",
    "\n",
    "# call function and write results in new column of the dataframe\n",
    "df.loc[:, 'CleanText'] = df['Text'].apply(\n",
    "    lambda x: do_preprocessing(x, True, True))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, afternoon, thanks, lot, take, question,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[okay, thats, helpful, growth, china, surpass,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "      <td>[hi, richard, so, gross, margin, look, pretty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[coreoncore, pretty, normal, well]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[okay, followup, ebit, dollar, growth, look, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[hi, mark, pat, thank, much, take, question, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[yes, im, wondering, could, talk, little, bit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[hi, thank, you, congrats, quarter, followup, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[thanks, squeeze, guy, question, you, john, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[one, area, obviously, strong, growth, driver,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label LabelNumber  \\\n",
       "0     [Question_1_Company_specific]           1   \n",
       "1     [Question_1_Company_specific]           1   \n",
       "2       [Question_1_Market_related]           2   \n",
       "3     [Question_1_Company_specific]           1   \n",
       "4     [Question_1_Company_specific]           1   \n",
       "...                             ...         ...   \n",
       "1304  [Question_1_Company_specific]           1   \n",
       "1305  [Question_1_Company_specific]           1   \n",
       "1306  [Question_1_Company_specific]           1   \n",
       "1307  [Question_1_Company_specific]           1   \n",
       "1308  [Question_1_Company_specific]           1   \n",
       "\n",
       "                                              CleanText  \n",
       "0     [good, afternoon, thanks, lot, take, question,...  \n",
       "1     [okay, thats, helpful, growth, china, surpass,...  \n",
       "2     [hi, richard, so, gross, margin, look, pretty,...  \n",
       "3                    [coreoncore, pretty, normal, well]  \n",
       "4     [okay, followup, ebit, dollar, growth, look, l...  \n",
       "...                                                 ...  \n",
       "1304  [hi, mark, pat, thank, much, take, question, c...  \n",
       "1305  [yes, im, wondering, could, talk, little, bit,...  \n",
       "1306  [hi, thank, you, congrats, quarter, followup, ...  \n",
       "1307  [thanks, squeeze, guy, question, you, john, kn...  \n",
       "1308  [one, area, obviously, strong, growth, driver,...  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for lemmatization\n",
    "def lemmatization(text):\n",
    "    \n",
    "  text = word_tokenize(text)\n",
    "  result=[]\n",
    "  wordnet = WordNetLemmatizer()\n",
    "  for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "\n",
    "  return result\n",
    "\n",
    "# call function\n",
    "df['CleanText'] = df['CleanText'].apply(\n",
    "    lambda x: lemmatization(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens back to strings for further processing\n",
    "string1=\" \"\n",
    "df['CleanText'] = df['CleanText'].apply(\n",
    "    lambda x: string1.join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_fraction = 0.70\n",
    "training_size = int(np.floor(len(df) * training_fraction))\n",
    "\n",
    "data_train, data_test = df[:training_size], df[training_size:]\n",
    "#X_train, X_test = data_train.drop(['monthly_stock_return'], axis = 1), data_test.drop(['monthly_stock_return'], axis = 1)\n",
    "#y_train, y_test = data_train[['monthly_stock_return']], data_test[['monthly_stock_return']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def do_bow(data):\n",
    "    count_vec = CountVectorizer()\n",
    "\n",
    "    bow = count_vec.fit_transform(data['CleanText'])\n",
    "    bow_matrix = pd.DataFrame(data = bow.toarray(), columns = count_vec.get_feature_names_out())\n",
    "\n",
    "    #display(bow_matrix)\n",
    "    \n",
    "    return(bow_matrix)\n",
    "\n",
    "# call function\n",
    "train_bow_matrix = do_bow(data_train)\n",
    "test_bow_matrix = do_bow(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def do_tfidf(data):\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "    tfidf = tfidf_vec.fit_transform(data['CleanText'])\n",
    "    tfidf_matrix = pd.DataFrame(data = tfidf.toarray(), columns = tfidf_vec.get_feature_names_out())\n",
    "\n",
    "    #display(tfidf_matrix)\n",
    "    \n",
    "    return(tfidf_matrix)\n",
    "\n",
    "# call function\n",
    "train_tfidf_matrix = do_tfidf(data_train)\n",
    "test_tfidf_matrix = do_tfidf(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def do_lsa(data):\n",
    "    num_components = 10\n",
    "    q, s, p = svds(tfidf, k = num_components)\n",
    "\n",
    "    lsa_doc_matrix = pd.DataFrame(data=q)\n",
    "\n",
    "    #display(lsa_doc_matrix)\n",
    "\n",
    "    return(lsa_doc_matrix)\n",
    "\n",
    "# call function\n",
    "train_lsa_matrix = do_lsa(train_tfidf_matrix)\n",
    "test_lsa_matrix = do_lsa(test_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "def do_doc2vec(data):\n",
    "    tagged_documents = []\n",
    "    sentences = [text.split() for text in data['CleanText']]\n",
    "\n",
    "    for i, doc in enumerate(sentences):\n",
    "        tagged_documents.append(gensim.models.doc2vec.TaggedDocument(doc, [i]))\n",
    "\n",
    "    d2v = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "    d2v.build_vocab(tagged_documents)\n",
    "\n",
    "    d2v.train(tagged_documents, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "    doc2vec_alldocs = []\n",
    "    for i in range(len(tagged_documents)):\n",
    "        doc2vec_alldocs.append(d2v.infer_vector(tagged_documents[i].words))\n",
    "\n",
    "    doc2vec_alldocs_matrix = pd.DataFrame(doc2vec_alldocs)\n",
    "\n",
    "    #display(doc2vec_alldocs_matrix)\n",
    "    \n",
    "    return(doc2vec_alldocs_matrix)\n",
    "\n",
    "# call function\n",
    "train_doc2vec_matrix = do_doc2vec(data_train) \n",
    "test_doc2vec_matrix = do_doc2vec(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Neural Network"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d39680e86271bf209db9aab97c2f2e95b8272895522c86f00c9979eddd8c4165"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
