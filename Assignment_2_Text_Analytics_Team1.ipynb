{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team information\n",
    "\n",
    "|Team-number :| 1|\n",
    "|:----:|:----:|\n",
    "\n",
    "\n",
    "|Name|    E-Mail        |matriculation-nr.|\n",
    "|:----:|:----:|:----:|\n",
    "|Tamara Scherer| schere21@ads.uni-passau.de|104218|\n",
    "|Felix Müller| muell518@ads.uni-passau.de|104227|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from label_studio_sdk import Client\n",
    "#from label_studio_sdk import project\n",
    "#from label_studio_sdk import project\n",
    "#import pandas as pd\n",
    "#LABEL_STUDIO_URL = 'http://132.231.59.226:8080' #this address needs to be the same as the address the label-studio is hosted on.\n",
    "#API_KEY = '1655a8922f821195356a17a3224c0532b091c61d' #please add your personal API_Key here to get your API_Key follow the Pictures below\n",
    "\n",
    "#ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "#ls.check_connection()\n",
    "#pro = project.Project.get_from_id(ls,\"1\")\n",
    "#tasks = project.Project.get_labeled_tasks(pro)\n",
    "#tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Files/tasks3\", 'rb') as f:\n",
    "    tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[QID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_2_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, I think that as it relates to the one, I t...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>One of the areas obviously which has been a st...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_1_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_2_positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_3_no_blame]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my ...   \n",
       "1       Good afternoon and thanks a lot for taking my...   \n",
       "2      Good afternoon and thanks a lot for taking my ...   \n",
       "3      Good afternoon and thanks a lot for taking my ...   \n",
       "4      No, I think that as it relates to the one, I t...   \n",
       "...                                                  ...   \n",
       "11289  One of the areas obviously which has been a st...   \n",
       "11290  Well, let's start with the first part of your ...   \n",
       "11291  Well, let's start with the first part of your ...   \n",
       "11292  Well, let's start with the first part of your ...   \n",
       "11293  Well, let's start with the first part of your ...   \n",
       "\n",
       "                               Label  \n",
       "0                            [QID_1]  \n",
       "1      [Question_1_Company_specific]  \n",
       "2              [Question_2_specific]  \n",
       "3               [Question_3_neutral]  \n",
       "4                            [AID_1]  \n",
       "...                              ...  \n",
       "11289           [Question_3_neutral]  \n",
       "11290                        [AID_1]  \n",
       "11291            [Answer_1_specific]  \n",
       "11292            [Answer_2_positive]  \n",
       "11293            [Answer_3_no_blame]  \n",
       "\n",
       "[11294 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Text', 'Label',])\n",
    "\n",
    "for i in range(len(tasks)): \n",
    "    for j in range(len(tasks[i]['annotations'][0]['result'])): \n",
    "        df = df.append({\n",
    "            'Text' : tasks[i]['annotations'][0]['result'][j]['value']['text'],\n",
    "            'Label' : tasks[i]['annotations'][0]['result'][j]['value']['labels']\n",
    "                        }, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\ts23\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ts23\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ts23\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "\n",
    "# import a stemmer for english words\n",
    "snowStem = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers \n",
    "Sample_Text = re.sub(r'\\d+', '', Sample_Text)\n",
    "print (Sample_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "Sample_Text = Sample_Text.translate(str.maketrans('','', string.punctuation))\n",
    "print(Sample_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading and ending white spaces\n",
    "Sample_Text = Sample_Text.strip()\n",
    "print(Sample_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "Sample_Text = snowStem.stem(Sample_Text)\n",
    "print(Sample_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "Sample_Text = ' '.join([w for w in Sample_Text.split() if not(w in STOPWORDS)])\n",
    "print(Sample_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_preprocessing(text_to_clean, remove_stopwords = True, stemming = False):\n",
    "    # remove numbers \n",
    "    text_to_clean = re.sub(r'\\d+', '', text_to_clean)\n",
    "    # remove punctuation\n",
    "    text_to_clean = text_to_clean.translate(str.maketrans('','', string.punctuation))\n",
    "    # remove leading and ending white spaces\n",
    "    text_to_clean = text_to_clean.strip()\n",
    "    # transform text to lower case\n",
    "    text_to_clean = text_to_clean.lower()\n",
    "\n",
    "    if stemming:\n",
    "      # stemming\n",
    "      text_to_clean = snowStem.stem(text_to_clean)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        # remove stop words\n",
    "        text_to_clean = ' '.join([w for w in text_to_clean.split() if not(w in STOPWORDS)])\n",
    "    \n",
    "    return text_to_clean\n",
    "\n",
    "\n",
    "for text in my_texts:\n",
    "  print(do_preprocessing(text))\n",
    "\n",
    "df.loc[:, 'clean_texts'] = [do_preprocessing(text, remove_stopwords = True) for text in df.content]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT WE HAVE TO DO:\n",
    "\n",
    "1x Bag-of-Words or tf-idf\n",
    "1x LDA or LSA\n",
    "1x GloVe, Word2Vec or Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "bow = count_vec.fit_transform(my_texts)\n",
    "pd.DataFrame(data = bow.toarray(), columns = count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "tfidf = tfidf_vec.fit_transform(tasks[0])\n",
    "pd.DataFrame(data = tfidf.toarray(), columns = tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "num_components = 10\n",
    "q, s, p = svds(tfidf, k = num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d39680e86271bf209db9aab97c2f2e95b8272895522c86f00c9979eddd8c4165"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
