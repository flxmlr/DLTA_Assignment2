{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team information\n",
    "\n",
    "|Team-number :| 1|\n",
    "|:----:|:----:|\n",
    "\n",
    "\n",
    "|Name|    E-Mail        |matriculation-nr.|\n",
    "|:----:|:----:|:----:|\n",
    "|Tamara Scherer| schere21@ads.uni-passau.de|104218|\n",
    "|Felix Müller| muell518@ads.uni-passau.de|104227|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labeling the data we now import it from the label-studio plattform. Therefore we used the provided workaround and downloaded the pickle file. In the next step we extract the necessary texts with the corresponding labels out of the whole downloaded data. A dataframe is created with the columns \"Text\" and \"Label\" in which the extracted data is saved. To be able to work more efficient with the data, we assign an unique ID to each label in the dataframe with the function \"categorise()\". This is especially helpful when we create the neural network in the end, as we can only use integer values as input. As stated in the task formulation we have to focus on one ID Stage. So, we implemented a filter to get only the entries with the desired ID Stage which can be specified before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary packages:\n",
    "> pickle: This package is used for serializing and de-serializing python object structures which means that any kind of python object is converted into byte streams or vice versa.\n",
    "\n",
    "> pandas: This package is usually used for data analysis and manipulation. It allows us to create and work with a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from label_studio_sdk import Client\n",
    "#from label_studio_sdk import project\n",
    "#from label_studio_sdk import project\n",
    "#import pandas as pd\n",
    "#LABEL_STUDIO_URL = 'http://132.231.59.226:8080' #this address needs to be the same as the address the label-studio is hosted on.\n",
    "#API_KEY = '1655a8922f821195356a17a3224c0532b091c61d' #please add your personal API_Key here to get your API_Key follow the Pictures below\n",
    "\n",
    "#ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "#ls.check_connection()\n",
    "#pro = project.Project.get_from_id(ls,\"1\")\n",
    "#tasks = project.Project.get_labeled_tasks(pro)\n",
    "#tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download labelled tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary package\n",
    "import pickle\n",
    "\n",
    "# import labeled data from downloaded pickle file\n",
    "with open(\"Files/tasks3\", 'rb') as f:\n",
    "    tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract text with label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[QID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_2_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, I think that as it relates to the one, I t...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>One of the areas obviously which has been a st...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[AID_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_1_specific]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_2_positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_3_no_blame]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my ...   \n",
       "1       Good afternoon and thanks a lot for taking my...   \n",
       "2      Good afternoon and thanks a lot for taking my ...   \n",
       "3      Good afternoon and thanks a lot for taking my ...   \n",
       "4      No, I think that as it relates to the one, I t...   \n",
       "...                                                  ...   \n",
       "11289  One of the areas obviously which has been a st...   \n",
       "11290  Well, let's start with the first part of your ...   \n",
       "11291  Well, let's start with the first part of your ...   \n",
       "11292  Well, let's start with the first part of your ...   \n",
       "11293  Well, let's start with the first part of your ...   \n",
       "\n",
       "                               Label  \n",
       "0                            [QID_1]  \n",
       "1      [Question_1_Company_specific]  \n",
       "2              [Question_2_specific]  \n",
       "3               [Question_3_neutral]  \n",
       "4                            [AID_1]  \n",
       "...                              ...  \n",
       "11289           [Question_3_neutral]  \n",
       "11290                        [AID_1]  \n",
       "11291            [Answer_1_specific]  \n",
       "11292            [Answer_2_positive]  \n",
       "11293            [Answer_3_no_blame]  \n",
       "\n",
       "[11294 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary package\n",
    "import pandas as pd\n",
    "\n",
    "# filter the necessary texts with the corresponding label\n",
    "df = pd.DataFrame(columns = ['Text', 'Label',])\n",
    "\n",
    "for i in range(len(tasks)): \n",
    "    for j in range(len(tasks[i]['annotations'][0]['result'])): \n",
    "        df = df.append({\n",
    "            'Text' : tasks[i]['annotations'][0]['result'][j]['value']['text'],\n",
    "            'Label' : tasks[i]['annotations'][0]['result'][j]['value']['labels']\n",
    "                        }, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Label as unique ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[QID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_2_specific]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my ...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, I think that as it relates to the one, I t...</td>\n",
       "      <td>[AID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>One of the areas obviously which has been a st...</td>\n",
       "      <td>[Question_3_neutral]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[AID_1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_1_specific]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_2_positive]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Well, let's start with the first part of your ...</td>\n",
       "      <td>[Answer_3_no_blame]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my ...   \n",
       "1       Good afternoon and thanks a lot for taking my...   \n",
       "2      Good afternoon and thanks a lot for taking my ...   \n",
       "3      Good afternoon and thanks a lot for taking my ...   \n",
       "4      No, I think that as it relates to the one, I t...   \n",
       "...                                                  ...   \n",
       "11289  One of the areas obviously which has been a st...   \n",
       "11290  Well, let's start with the first part of your ...   \n",
       "11291  Well, let's start with the first part of your ...   \n",
       "11292  Well, let's start with the first part of your ...   \n",
       "11293  Well, let's start with the first part of your ...   \n",
       "\n",
       "                               Label  LabelNumber  \n",
       "0                            [QID_1]            0  \n",
       "1      [Question_1_Company_specific]            1  \n",
       "2              [Question_2_specific]            3  \n",
       "3               [Question_3_neutral]            7  \n",
       "4                            [AID_1]            0  \n",
       "...                              ...          ...  \n",
       "11289           [Question_3_neutral]            7  \n",
       "11290                        [AID_1]            0  \n",
       "11291            [Answer_1_specific]            8  \n",
       "11292            [Answer_2_positive]           10  \n",
       "11293            [Answer_3_no_blame]           13  \n",
       "\n",
       "[11294 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign a unique number to each label (can also be used later for the neural network)\n",
    "def categorise(row):  \n",
    "    if row['Label'] == ['Question_1_Company_specific']:\n",
    "        return 1\n",
    "    elif row['Label'] == ['Question_1_Market_related']:\n",
    "        return 2\n",
    "    elif row['Label'] == ['Question_2_specific']:\n",
    "        return 3\n",
    "    elif row['Label'] == ['Question_2_open']:\n",
    "        return 4\n",
    "    elif row['Label'] == ['Question_3_attack']:\n",
    "        return 5\n",
    "    elif row['Label'] == ['Question_3_support']:\n",
    "        return 6\n",
    "    elif row['Label'] == ['Question_3_neutral']:\n",
    "        return 7\n",
    "    elif row['Label'] == ['Answer_1_specific']:\n",
    "        return 8\n",
    "    elif row['Label'] == ['Answer_1_avoid_excuse']:\n",
    "        return 9\n",
    "    elif row['Label'] == ['Answer_2_positive']:\n",
    "        return 10\n",
    "    elif row['Label'] == ['Answer_2_negative']:\n",
    "        return 11\n",
    "    elif row['Label'] == ['Answer_3_blame']:\n",
    "        return 12\n",
    "    elif row['Label'] == ['Answer_3_no_blame']:\n",
    "        return 13\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "# call function and write results in a new column of the dataframe\n",
    "df['LabelNumber'] = df.apply(\n",
    "    lambda row: categorise(row), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter one ID stage (e.g. Question_1_XX)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label  LabelNumber  \n",
       "0     [Question_1_Company_specific]            1  \n",
       "1     [Question_1_Company_specific]            1  \n",
       "2       [Question_1_Market_related]            2  \n",
       "3     [Question_1_Company_specific]            1  \n",
       "4     [Question_1_Company_specific]            1  \n",
       "...                             ...          ...  \n",
       "1304  [Question_1_Company_specific]            1  \n",
       "1305  [Question_1_Company_specific]            1  \n",
       "1306  [Question_1_Company_specific]            1  \n",
       "1307  [Question_1_Company_specific]            1  \n",
       "1308  [Question_1_Company_specific]            1  \n",
       "\n",
       "[1309 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set desired labels\n",
    "idStage = [1, 2]\n",
    "\n",
    "# filter the entries in the dataframe with the specified ID stage\n",
    "df = df[df['LabelNumber'].isin(idStage)]\n",
    "\n",
    "# set new index\n",
    "df = df.reset_index()\n",
    "# delete old indices\n",
    "df.pop('index')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelID = 1 --> 919\n",
    "# LabelID = 2 --> 390"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement different steps to preprocess the downloaded data. Therefore we have to make some imports first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Packages:\n",
    "> re: This package can be used to work with Regular Expressions. Here it is used remove the numbers in the text.\n",
    "\n",
    "> string: This package is necessary for common string operations. Here it is used to remove the punctuation in the text.\n",
    "\n",
    "> nltk: Natural Language Toolkit is a package which is used for Natural Language Processing. Here it is used for stemming, lemmatization, tokenization and the removal of stopwords.\n",
    "\n",
    "Further Imports:\n",
    "> For Stemmer: The module \"nltk.stem.snowball\" provides a port of the Snowball stemmers. The word stemmer is based on the original Porter stemming algorithm for suffix stripping. In this case it is used for the English language.\n",
    "\n",
    "> For Stopwords: Here the English stopwords are imported from the \"nltk.corpus\" package. It includes words which does not add much meaning to a sentence and are not important for further text analysis.\n",
    "\n",
    "> For Tokenization: The word_tokenize module is imported from the nltk library for tokenization.\n",
    "\n",
    "> For Lemmatizer: The \"WordNetLemmatizer\" module as well as \"pos_tag\" is imported here. Therefore the system requires some further downloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we start with the preprocessing. Therefore, we implemented a function called \"do_preprocessing\" with text that has to be preprocessed as input. Furthermore, it is possible to set two boolean values to specify if the removal of stopwords and the stemming should be executed. \n",
    "Within the function we implemented the following steps:\n",
    "1. Removal of Numbers: delete all numbers, e.g. 1, 2 of the text\n",
    "2. Lowercasing: convert the text into the same casing, so that the different versions of the word can be treated as one\n",
    "3. Stemming: process to reduce the words to their root forms, but the stem itself may not be a valid word in the language (here we use the PorterStemmer)\n",
    "4. Stopwords Removal: stopwords are trivial words which appear very frequently in the text without adding much valuable information and therefore not necessary for the further analysis\n",
    "5. Removing Punctuations: the punctuation does not add any value, so it is not necessary or helpful for the analysis and can therefore be deleted as well\n",
    "6. Removing Extra Whitespaces: additional whitespaces do not add any value to the data and just increase the text size, so they can be deleted as well\n",
    "<p>\n",
    "For Lemmatization we implemented another function \"do_lemmatization\" as it is necessary to do a tokenization first.\n",
    "\n",
    "1. Tokenization: process of splitting the text into pieces called tokens (here the tokens are the single words)\n",
    "2. Lemmatization: This can be done instead of stemming. Lemmatization is also a process to convert the word to its base form. Before the text is lemmatized a POS tagging is necessary to tag the tokens as noun, verb, adverb or adjective. As it causes noticeable improvement we implement the lemmatization in addition to the already implemented preprocessing.\n",
    "<p>\n",
    "Finally we use the resulting tokens to create a dictionary which is necessary for the following steps as for building the neural network the column size of the training and test dataset have to be identical. This can be ensured by using this dictionary. To be able to execute the next implementations it is necessary to convert the tokens back to normal strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ts23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# necessary imports for preprocessing steps\n",
    "\n",
    "# import necessary packages\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# import a stemmer for english words\n",
    "snowStem = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "# import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# import for tokenization\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# import for lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>good afternoon thanks lot taking question so r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay thats helpful growth china surpass expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "      <td>hi richard so gross margin looked pretty solid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>coreoncore pretty normal well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay followup ebit dollar growth looked like c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi mark pat thank much taking question could t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>yes im wondering could talk little bit custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi thank you congrats quarter followup toms qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>thanks squeezing guys question you john know g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>one areas obviously strong growth driver team ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label  LabelNumber  \\\n",
       "0     [Question_1_Company_specific]            1   \n",
       "1     [Question_1_Company_specific]            1   \n",
       "2       [Question_1_Market_related]            2   \n",
       "3     [Question_1_Company_specific]            1   \n",
       "4     [Question_1_Company_specific]            1   \n",
       "...                             ...          ...   \n",
       "1304  [Question_1_Company_specific]            1   \n",
       "1305  [Question_1_Company_specific]            1   \n",
       "1306  [Question_1_Company_specific]            1   \n",
       "1307  [Question_1_Company_specific]            1   \n",
       "1308  [Question_1_Company_specific]            1   \n",
       "\n",
       "                                              CleanText  \n",
       "0     good afternoon thanks lot taking question so r...  \n",
       "1     okay thats helpful growth china surpass expect...  \n",
       "2     hi richard so gross margin looked pretty solid...  \n",
       "3                         coreoncore pretty normal well  \n",
       "4     okay followup ebit dollar growth looked like c...  \n",
       "...                                                 ...  \n",
       "1304  hi mark pat thank much taking question could t...  \n",
       "1305  yes im wondering could talk little bit custome...  \n",
       "1306  hi thank you congrats quarter followup toms qu...  \n",
       "1307  thanks squeezing guys question you john know g...  \n",
       "1308  one areas obviously strong growth driver team ...  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that includes all preprocessing steps\n",
    "\n",
    "def do_preprocessing(text_to_clean, remove_stopwords = True, stemming = True):\n",
    "    # remove numbers \n",
    "    text_to_clean = re.sub(r'\\d+', '', text_to_clean)\n",
    "    # transform text to lower case\n",
    "    text_to_clean = text_to_clean.lower()\n",
    "\n",
    "    if stemming:\n",
    "      # stemming\n",
    "      text_to_clean = snowStem.stem(text_to_clean)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        # remove stop words\n",
    "        text_to_clean = ' '.join([w for w in text_to_clean.split() if not(w in en_stopwords)])\n",
    "\n",
    "    # remove punctuation\n",
    "    text_to_clean = text_to_clean.translate(str.maketrans('','', string.punctuation))\n",
    "    # remove leading and ending white spaces\n",
    "    text_to_clean = text_to_clean.strip()\n",
    "    \n",
    "    return text_to_clean\n",
    "\n",
    "\n",
    "# call function and write results in new column of the dataframe\n",
    "df.loc[:, 'CleanText'] = df['Text'].apply(\n",
    "    lambda x: do_preprocessing(x, True, True))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, afternoon, thanks, lot, take, question,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[okay, thats, helpful, growth, china, surpass,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "      <td>[hi, richard, so, gross, margin, look, pretty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[coreoncore, pretty, normal, well]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[okay, followup, ebit, dollar, growth, look, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[hi, mark, pat, thank, much, take, question, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[yes, im, wondering, could, talk, little, bit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[hi, thank, you, congrats, quarter, followup, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[thanks, squeeze, guy, question, you, john, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>[one, area, obviously, strong, growth, driver,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label  LabelNumber  \\\n",
       "0     [Question_1_Company_specific]            1   \n",
       "1     [Question_1_Company_specific]            1   \n",
       "2       [Question_1_Market_related]            2   \n",
       "3     [Question_1_Company_specific]            1   \n",
       "4     [Question_1_Company_specific]            1   \n",
       "...                             ...          ...   \n",
       "1304  [Question_1_Company_specific]            1   \n",
       "1305  [Question_1_Company_specific]            1   \n",
       "1306  [Question_1_Company_specific]            1   \n",
       "1307  [Question_1_Company_specific]            1   \n",
       "1308  [Question_1_Company_specific]            1   \n",
       "\n",
       "                                              CleanText  \n",
       "0     [good, afternoon, thanks, lot, take, question,...  \n",
       "1     [okay, thats, helpful, growth, china, surpass,...  \n",
       "2     [hi, richard, so, gross, margin, look, pretty,...  \n",
       "3                    [coreoncore, pretty, normal, well]  \n",
       "4     [okay, followup, ebit, dollar, growth, look, l...  \n",
       "...                                                 ...  \n",
       "1304  [hi, mark, pat, thank, much, take, question, c...  \n",
       "1305  [yes, im, wondering, could, talk, little, bit,...  \n",
       "1306  [hi, thank, you, congrats, quarter, followup, ...  \n",
       "1307  [thanks, squeeze, guy, question, you, john, kn...  \n",
       "1308  [one, area, obviously, strong, growth, driver,...  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for lemmatization\n",
    "def do_lemmatization(text):\n",
    "    \n",
    "  text = word_tokenize(text)\n",
    "  \n",
    "  result=[]\n",
    "  wordnet = WordNetLemmatizer()\n",
    "  for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "\n",
    "  return result\n",
    "\n",
    "# call function\n",
    "df['CleanText'] = df['CleanText'].apply(\n",
    "    lambda x: do_lemmatization(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# generate the gensim dictionary\n",
    "dct = corpora.dictionary.Dictionary(df['CleanText']).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert tokens to strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelNumber</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon and thanks a lot for taking my...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>good afternoon thanks lot take question so rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, that's very helpful. And then on your gr...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay thats helpful growth china surpass expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Richard. So, on gross margin, it looked pre...</td>\n",
       "      <td>[Question_1_Market_related]</td>\n",
       "      <td>2</td>\n",
       "      <td>hi richard so gross margin look pretty solid w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the core-on-core was pretty normal for you...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>coreoncore pretty normal well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. And my follow-up is on the EBIT dollar ...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>okay followup ebit dollar growth look like com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Hi. This is Mark for Pat. Thank you so much fo...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi mark pat thank much take question could tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Yes. I'm just wondering if you could talk a li...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>yes im wondering could talk little bit custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Hi, thank you. Congrats on the quarter. Just a...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>hi thank you congrats quarter followup tom que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Thanks for squeezing me in guys. This question...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>thanks squeeze guy question you john know guy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>One of the areas obviously which has been a s...</td>\n",
       "      <td>[Question_1_Company_specific]</td>\n",
       "      <td>1</td>\n",
       "      <td>one area obviously strong growth driver team m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0      Good afternoon and thanks a lot for taking my...   \n",
       "1     Okay, that's very helpful. And then on your gr...   \n",
       "2     Hi Richard. So, on gross margin, it looked pre...   \n",
       "3     And the core-on-core was pretty normal for you...   \n",
       "4      Okay. And my follow-up is on the EBIT dollar ...   \n",
       "...                                                 ...   \n",
       "1304  Hi. This is Mark for Pat. Thank you so much fo...   \n",
       "1305  Yes. I'm just wondering if you could talk a li...   \n",
       "1306  Hi, thank you. Congrats on the quarter. Just a...   \n",
       "1307  Thanks for squeezing me in guys. This question...   \n",
       "1308   One of the areas obviously which has been a s...   \n",
       "\n",
       "                              Label  LabelNumber  \\\n",
       "0     [Question_1_Company_specific]            1   \n",
       "1     [Question_1_Company_specific]            1   \n",
       "2       [Question_1_Market_related]            2   \n",
       "3     [Question_1_Company_specific]            1   \n",
       "4     [Question_1_Company_specific]            1   \n",
       "...                             ...          ...   \n",
       "1304  [Question_1_Company_specific]            1   \n",
       "1305  [Question_1_Company_specific]            1   \n",
       "1306  [Question_1_Company_specific]            1   \n",
       "1307  [Question_1_Company_specific]            1   \n",
       "1308  [Question_1_Company_specific]            1   \n",
       "\n",
       "                                              CleanText  \n",
       "0     good afternoon thanks lot take question so rec...  \n",
       "1     okay thats helpful growth china surpass expect...  \n",
       "2     hi richard so gross margin look pretty solid w...  \n",
       "3                         coreoncore pretty normal well  \n",
       "4     okay followup ebit dollar growth look like com...  \n",
       "...                                                 ...  \n",
       "1304  hi mark pat thank much take question could tal...  \n",
       "1305  yes im wondering could talk little bit custome...  \n",
       "1306  hi thank you congrats quarter followup tom que...  \n",
       "1307  thanks squeeze guy question you john know guy ...  \n",
       "1308  one area obviously strong growth driver team m...  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tokens back to strings for further processing\n",
    "whitespace = \" \"\n",
    "df['CleanText'] = df['CleanText'].apply(\n",
    "    lambda x: whitespace.join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split of training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the neural network which we build later on, it is necessary to split the available data in a training and a test dataset. We therefore use the 70/30-approach which means that 70% of the data is used for training and 30% of the data is used for testing. \n",
    "We do this split already in this step to ensure that there are no dependencies between training and test dataset in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary package:\n",
    "> numpy: Provides operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, basic linear algebra and much more. We use it here to compute the training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#training_fraction = 0.70\n",
    "#training_size = int(np.floor(len(df) * training_fraction))\n",
    "\n",
    "#data_train, data_test = df[:training_size], df[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# we arbitrarily use a training fraction of 70%\n",
    "train_size = int(0.70 * len(df))\n",
    "\n",
    "# select random index numbers and split the data accordingly\n",
    "random.seed(42)\n",
    "train_select = random.sample(list(df.index), k = train_size)\n",
    "train_idx = [i for i in list(df.index) if i in train_select]\n",
    "test_idx = [i for i in list(df.index) if not(i in train_select)]\n",
    "data_train = df.iloc[train_idx, :]\n",
    "data_test = df.iloc[test_idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Frequency Method: Bag-of-Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach the number of terms per document are counted. As we have a big corpora in this case, the resulting document-term matrix is a sparse matrix which means that it has many zeros and only a few non-zeor entries.\n",
    "The method \"CountVectorizer()\" converts a collection of text documents to a matrix of token counts. The result out of this is a sparse representation of the counts which then have to be transformed into an array. Finally, this array is converted in a DataFrame. \n",
    "As already mentioned before, we have created a dictionary out of all the existing tokens after the preprocessing. This dictionary can now be used as input for the CountVectorizer() to get BOW-matrices with the same amount of columns.\n",
    "<p>\n",
    "Necessary Package: \n",
    "\n",
    "> sklearn.feature_extraction.text.CountVectorizer: Used to convert a collection of text documents to a matrix of token counts. It produces a sparse representation of the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afternoon</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>benefit</th>\n",
       "      <th>decision</th>\n",
       "      <th>different</th>\n",
       "      <th>do</th>\n",
       "      <th>drive</th>\n",
       "      <th>give</th>\n",
       "      <th>good</th>\n",
       "      <th>growth</th>\n",
       "      <th>...</th>\n",
       "      <th>realignment</th>\n",
       "      <th>rpo</th>\n",
       "      <th>shed</th>\n",
       "      <th>asics</th>\n",
       "      <th>hock</th>\n",
       "      <th>jericho</th>\n",
       "      <th>optical</th>\n",
       "      <th>performing</th>\n",
       "      <th>tomahawk</th>\n",
       "      <th>trident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows × 4495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     afternoon  anniversary  benefit  decision  different  do  drive  give  \\\n",
       "0            1            1        1         1          1   1      2     1   \n",
       "1            0            0        0         0          0   0      0     0   \n",
       "2            0            0        0         0          0   0      0     0   \n",
       "3            0            0        0         0          0   0      0     0   \n",
       "4            0            0        0         0          0   0      0     1   \n",
       "..         ...          ...      ...       ...        ...  ..    ...   ...   \n",
       "911          0            0        0         0          0   0      0     1   \n",
       "912          1            0        0         0          0   0      0     0   \n",
       "913          0            0        0         0          0   0      0     0   \n",
       "914          0            0        0         0          0   0      0     1   \n",
       "915          0            0        0         0          0   0      0     0   \n",
       "\n",
       "     good  growth  ...  realignment  rpo  shed  asics  hock  jericho  optical  \\\n",
       "0       1       2  ...            0    0     0      0     0        0        0   \n",
       "1       0       1  ...            0    0     0      0     0        0        0   \n",
       "2       0       0  ...            0    0     0      0     0        0        0   \n",
       "3       0       2  ...            0    0     0      0     0        0        0   \n",
       "4       0       0  ...            0    0     0      0     0        0        0   \n",
       "..    ...     ...  ...          ...  ...   ...    ...   ...      ...      ...   \n",
       "911     0       0  ...            0    0     0      0     0        0        0   \n",
       "912     1       0  ...            0    0     0      0     0        0        0   \n",
       "913     0       0  ...            0    0     0      0     0        0        0   \n",
       "914     0       0  ...            0    2     1      0     0        0        0   \n",
       "915     0       1  ...            0    0     0      1     1        1        1   \n",
       "\n",
       "     performing  tomahawk  trident  \n",
       "0             0         0        0  \n",
       "1             0         0        0  \n",
       "2             0         0        0  \n",
       "3             0         0        0  \n",
       "4             0         0        0  \n",
       "..          ...       ...      ...  \n",
       "911           0         0        0  \n",
       "912           0         0        0  \n",
       "913           0         0        0  \n",
       "914           0         0        0  \n",
       "915           1         1        1  \n",
       "\n",
       "[916 rows x 4495 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afternoon</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>benefit</th>\n",
       "      <th>decision</th>\n",
       "      <th>different</th>\n",
       "      <th>do</th>\n",
       "      <th>drive</th>\n",
       "      <th>give</th>\n",
       "      <th>good</th>\n",
       "      <th>growth</th>\n",
       "      <th>...</th>\n",
       "      <th>realignment</th>\n",
       "      <th>rpo</th>\n",
       "      <th>shed</th>\n",
       "      <th>asics</th>\n",
       "      <th>hock</th>\n",
       "      <th>jericho</th>\n",
       "      <th>optical</th>\n",
       "      <th>performing</th>\n",
       "      <th>tomahawk</th>\n",
       "      <th>trident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 4495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     afternoon  anniversary  benefit  decision  different  do  drive  give  \\\n",
       "0            0            0        0         0          0   0      0     0   \n",
       "1            0            0        0         0          0   0      0     0   \n",
       "2            0            0        0         0          0   0      0     1   \n",
       "3            1            0        0         0          0   0      0     0   \n",
       "4            0            0        0         0          0   0      0     0   \n",
       "..         ...          ...      ...       ...        ...  ..    ...   ...   \n",
       "388          1            0        0         0          0   0      0     0   \n",
       "389          0            0        0         0          0   0      0     0   \n",
       "390          0            0        0         0          0   0      1     1   \n",
       "391          0            0        0         0          0   0      0     0   \n",
       "392          0            0        0         0          0   0      0     0   \n",
       "\n",
       "     good  growth  ...  realignment  rpo  shed  asics  hock  jericho  optical  \\\n",
       "0       0       0  ...            0    0     0      0     0        0        0   \n",
       "1       0       0  ...            0    0     0      0     0        0        0   \n",
       "2       0       0  ...            0    0     0      0     0        0        0   \n",
       "3       1       0  ...            0    0     0      0     0        0        0   \n",
       "4       0       0  ...            0    0     0      0     0        0        0   \n",
       "..    ...     ...  ...          ...  ...   ...    ...   ...      ...      ...   \n",
       "388     1       0  ...            0    0     0      0     0        0        0   \n",
       "389     0       0  ...            0    0     0      0     0        0        0   \n",
       "390     1       4  ...            0    0     0      0     0        0        0   \n",
       "391     0       0  ...            0    0     0      0     0        0        0   \n",
       "392     0       0  ...            1    0     0      0     0        0        0   \n",
       "\n",
       "     performing  tomahawk  trident  \n",
       "0             0         0        0  \n",
       "1             0         0        0  \n",
       "2             0         0        0  \n",
       "3             0         0        0  \n",
       "4             0         0        0  \n",
       "..          ...       ...      ...  \n",
       "388           0         0        0  \n",
       "389           0         0        0  \n",
       "390           0         0        0  \n",
       "391           0         0        0  \n",
       "392           0         0        0  \n",
       "\n",
       "[393 rows x 4495 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def do_bow(data):\n",
    "    count_vec = CountVectorizer(vocabulary = dct)\n",
    "\n",
    "    bow = count_vec.fit_transform(data['CleanText'])\n",
    "    bow_matrix = pd.DataFrame(data = bow.toarray(), columns = count_vec.get_feature_names_out())\n",
    "\n",
    "    display(bow_matrix)\n",
    "    \n",
    "    return(bow_matrix)\n",
    "\n",
    "# call function\n",
    "train_bow_matrix = do_bow(data_train)\n",
    "test_bow_matrix = do_bow(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Frequency Method: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another raw frequency-based approach is TF-IDF (= term-frequency inverse-docmument-frequency). Instead of using the absolute term frequencies, we use weighted frequencies for this method.\n",
    "It is working very similar to the implementation of BOW. For this method the \"TfidfVectorizer()\" can be used which has again the parameter vocabulary which we set to the created dictionary. The TfidfVectorizer converts a collection of raw documents to a matrix of TF-IDF features. We again get a sparse matrix which we then transform into an array and pass it into a DataFrame which is then given as output of the function.\n",
    "<p>\n",
    "Necessary package: \n",
    "\n",
    "> sklearn.feature_extraction.text.TfidfVectorizer: used to transform a count matrix to a normalized tf or tf-idf representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def do_tfidf(data):\n",
    "    tfidf_vec = TfidfVectorizer(vocabulary = dct)\n",
    "\n",
    "    tfidf = tfidf_vec.fit_transform(data['CleanText'])\n",
    "    tfidf_matrix = pd.DataFrame(data = tfidf.toarray(), columns = tfidf_vec.get_feature_names_out())\n",
    "\n",
    "    display(tfidf_matrix)\n",
    "    \n",
    "    return(tfidf_matrix)\n",
    "\n",
    "# call function\n",
    "train_tfidf_matrix = do_tfidf(data_train)\n",
    "test_tfidf_matrix = do_tfidf(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Topic Method: LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA (= latent semantic analysis) is one representative of topic-based approaches. It is a mathematical decomposition technique using raw frequency matrices. As already mentioned, BOW or TF-IDF matrices can be very spare and high dimensional. LSA is facing this problem by reducing the dimensionality.\n",
    "Therefore, the resulting matrix of BOW or TF-IDF is necessary which we already get as output of the corresponding functions. So, we use for example the tf-idf-matrix as input for this function. Then we set the number of topics and apply singular value decomposition to the matrix which can be done for example by the function \"svds\".\n",
    "<p>\n",
    "Necessary Package:\n",
    "\n",
    "> scipy.sparse.linalg.svds: It is used to make a partial singular value decomposition of a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def do_lsa(data):\n",
    "    num_components = 10\n",
    "    q, s, p = svds(data, k = num_components)\n",
    "\n",
    "    lsa_doc_matrix = pd.DataFrame(data=q)\n",
    "\n",
    "    display(lsa_doc_matrix)\n",
    "\n",
    "    return(lsa_doc_matrix)\n",
    "\n",
    "# call function\n",
    "train_lsa_matrix = do_lsa(train_tfidf_matrix)\n",
    "test_lsa_matrix = do_lsa(test_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Word Embedding Method: Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Doc2Vec method it is possible to derive document vectors. As opposite to Word2Vec it is used to create a vectorized representation of a group of words taken collectively as a single unit.\n",
    "First of all we have to train the model. In order to do this we need the tagged document which can be created by using \"models.doc2vec.TaggedDocument()\". In the next step we initialise the model, build the vocabulary and train the Doc2Vec model. Finally, we can use the model.infer_vector() to analyse the output and save the matrix as a DataFrame.\n",
    "\n",
    "<p>\n",
    "Necessary Package:\n",
    "\n",
    "> gensim: Used for topic modelling, document indexing and similarity retrieval with large corpora. The target audience is the natural language processing and information retrieval community.\n",
    "\n",
    "> gensim.models.doc2vec.Doc2Vec: Necessary to build the Doc2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "def do_doc2vec(data):\n",
    "    tagged_documents = []\n",
    "    sentences = [text.split() for text in data['CleanText']]\n",
    "    doc2vec_alldocs = []\n",
    "\n",
    "    # train the doc2vec\n",
    "    for i, doc in enumerate(sentences):\n",
    "        tagged_documents.append(gensim.models.doc2vec.TaggedDocument(doc, [i]))\n",
    "\n",
    "    # initialize the model\n",
    "    d2v = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "    # build the vocabulary\n",
    "    d2v.build_vocab(tagged_documents)\n",
    "\n",
    "    # train the doc2vec model\n",
    "    d2v.train(tagged_documents, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "    # create Doc2Vec-matrix out of all documents and pass it into a DataFrame\n",
    "    for i in range(len(tagged_documents)):\n",
    "        doc2vec_alldocs.append(d2v.infer_vector(tagged_documents[i].words))\n",
    "    doc2vec_alldocs_matrix = pd.DataFrame(doc2vec_alldocs)\n",
    "\n",
    "    display(doc2vec_alldocs_matrix)\n",
    "    \n",
    "    return(doc2vec_alldocs_matrix)\n",
    "\n",
    "# call function\n",
    "train_doc2vec_matrix = do_doc2vec(data_train) \n",
    "test_doc2vec_matrix = do_doc2vec(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generating a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step we have to create a neural network to generate a target model that tries to predict the correct label for a text. Therefore we first define the neural network. By compilation we define the loww function which is supposed to be minimized and which optimization method should be used. Before we can fit the model, we have to convert the independent variables to an array. In the end we plot the results and calculate the correlation coefficients for the training and test data. <p>\n",
    "As input for the function we use the prepared dataframe with the preprocessed data and the output of BOW/TF-IDF/LSA/Doc2Vec.\n",
    "\n",
    "\n",
    "<p>\n",
    "Necessary Packages:\n",
    "\n",
    "> tensorflow: Provides various tools for machine learning applications. We need it in the following to generate the neural networks.\n",
    "\n",
    "> matplotlib.pyplot: It is used for plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(data_train['LabelNumber'].values.tolist())\n",
    "test_y = np.array(data_test['LabelNumber'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow_matrix = np.asarray(train_bow_matrix)\n",
    "test_bow_matrix = np.asarray(test_bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define function to create a neural network\n",
    "def build_nn(train_X, train_y, test_X, test_y):\n",
    "\n",
    "    # first we define the network, units is the number of neurons, in the first layer we need to tell the model the input shape\n",
    "    neural_network = tf.keras.Sequential([\n",
    "                        # hidden layer\n",
    "                        tf.keras.layers.Dense(units = 100, input_shape = [train_X.shape[1]], activation = 'selu'),\n",
    "                        # output layer - as we want probability predictions, it is important to use the sigmoid activation\n",
    "                        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    # compilation\n",
    "    neural_network.compile(loss = 'binary_crossentropy', optimizer = 'sgd',  metrics = ['accuracy', tf.keras.metrics.Recall()])\n",
    "\n",
    "    # a summary for all parameters which need to be estimated\n",
    "    neural_network.summary()\n",
    "\n",
    "    # convert input to array for the model fit\n",
    "    train_X = np.asarray(train_X)\n",
    "    test_X = np.asarray(test_X)\n",
    "\n",
    "    # we fit the model, epochs is the number of steps which are repeated using gradient descent\n",
    "    history = neural_network.fit(train_X, train_y, epochs = 100, validation_data = (test_X, test_y))\n",
    "    plt.plot(history.history['loss'], label = 'training'), plt.plot(history.history['val_loss'], label = 'test'), plt.legend(loc='lower left'), plt.show()\n",
    "\n",
    "    # correlation coefficient of training and test data\n",
    "    corrcoef_train = np.corrcoef(neural_network.predict(train_X).flatten(), train_y)[0, 1]    \n",
    "    print(\"Correlation coefficient train-data:\", corrcoef_train)\n",
    "    \n",
    "    corrcoef_test = np.corrcoef(neural_network.predict(test_X).flatten(), test_y)[0, 1]\n",
    "    print(\"Correlation coefficient test-data:\", corrcoef_test)\n",
    "\n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               449600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449,701\n",
      "Trainable params: 449,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 18ms/step - loss: -0.0619 - accuracy: 0.6998 - recall: 0.9858 - val_loss: -0.5748 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -0.8873 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1.2529 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -1.5650 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1.9711 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -2.3517 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2.8579 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -3.3421 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -3.9931 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -4.6093 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -5.4460 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: -6.2226 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -7.2874 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: -8.2612 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -9.6212 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: -10.8360 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -12.5640 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: -14.0798 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -16.2306 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -18.1343 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -20.8587 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -23.2781 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -26.6753 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -29.7817 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -34.1233 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -38.1901 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -43.8069 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -49.2118 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -56.4676 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -63.7341 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -73.2439 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -83.1301 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -95.8644 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -109.4611 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -126.4281 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -145.2773 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -168.3074 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -194.5884 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -226.1387 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -263.0263 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -306.0869 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -357.8744 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -417.5986 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -490.5215 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -574.3763 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -677.3190 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -792.6676 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -937.9747 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1100.2819 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -1305.2224 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1529.4613 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -1818.5629 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2135.9199 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -2543.4121 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2981.2351 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -3555.4399 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -4182.5488 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -4995.0830 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -5873.9272 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -7020.1509 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -8242.9160 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -9859.7754 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -11567.3965 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -13842.0068 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -16318.2520 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -19530.0352 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -23029.6641 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -27569.6484 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -32542.7988 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -38952.3789 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -45792.7891 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -54825.1484 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -64539.9492 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -77310.0469 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -91209.9609 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -109255.3594 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -128884.5938 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -154414.0156 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -181659.8750 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -217622.8125 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -256239.1250 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -306997.2500 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -361154.3750 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -432580.0938 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -508026.3750 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -608398.3125 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -714622.7500 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -856021.4375 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1006909.7500 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -1206232.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1422075.8750 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -1703251.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2010370.2500 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -2408562.2500 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2844598.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -3408455.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -4002259.7500 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -4794686.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -5639581.5000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -6756033.5000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -7961767.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -9537197.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -11205596.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -13424781.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -15822410.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -18953560.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -22286776.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -26686538.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -31507868.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -37745328.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -44395408.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -53190280.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -62727508.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -75157216.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -88384040.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -105859072.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -124633712.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -149315792.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -175695120.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -210496688.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -248137424.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -297283520.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -350344448.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -419809920.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -493855616.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -591785152.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -697019520.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -835036224.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -982471616.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -1177273216.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1384105728.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -1658241920.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1954436096.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -2341499904.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2753908480.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -3299631104.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -3885363712.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -4654911488.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -5489425408.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -6577710592.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -7752365056.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -9286056960.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -10989119488.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -13160801280.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -15535867904.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -18609756160.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -21933185024.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -26268188672.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -30856628224.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -36971577344.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -43611963392.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -52255838208.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -61538848768.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -73715875840.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -86791266304.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -103968071680.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -122440531968.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -146724241408.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -172532858880.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -206747451392.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -242985041920.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -291127656448.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -342312681472.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -410272464896.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -483644604416.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -579502276608.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -682829742080.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -817879908352.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -961761378304.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -1152446627840.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1358621179904.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: -1627685519360.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -1919133417472.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -2299076280320.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -2709924347904.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: -3246534688768.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -3816424734720.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -4572264792064.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -5369365004288.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -6434157756416.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -7578287341568.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -9077854830592.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -10681299501056.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -12795739373568.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -15038499782656.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -18018128101376.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -21258087432192.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -25471922208768.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -30023165673472.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -35965213081600.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -42418439192576.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -50822025052160.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -60001842364416.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -71880698494976.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -84648940011520.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -101410964242432.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -119288698503168.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: -142881666891776.0000 - accuracy: 0.7063 - recall: 1.0000 - val_loss: -168690796462080.0000 - val_accuracy: 0.6921 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient train-data: nan\n",
      "Correlation coefficient test-data: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ts23\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\ts23\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "nn_bow = build_nn(train_bow_matrix, train_y, test_bow_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tfidf = build_nn(train_tfidf_matrix, train_y, test_tfidf_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lsa = build_nn(train_lsa_matrix, train_y, test_lsa_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_doc2vec = build_nn(train_doc2vec_matrix, train_y, test_doc2vec_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def undersampling(data):\n",
    "    rus = RandomUnderSampler(sampling_strategy=1)\n",
    "    data_res, label_res = rus.fit_resample(data, data['LabelNumber'])\n",
    "\n",
    "    ax = data_res['LabelNumber'].value_counts().plot.pie()\n",
    "    display(data_res)\n",
    "    return data_res\n",
    "\n",
    "df = undersampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "neural_network = nn_bow\n",
    "\n",
    "# let us take a look at the confusion matrix, remember predictions are 1 if the predicted proability for class 1 is higher than 0.5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "train_cm = confusion_matrix(train_y, (neural_network.predict(train_bow_matrix) > 0.50).ravel() * 1)\n",
    "sn.heatmap(train_cm, annot = True, cmap='Greens', ax = axs[0])\n",
    "\n",
    "axs[0].set_xlabel('Predictions')\n",
    "axs[0].set_ylabel('True Labels')\n",
    "axs[0].set_title('Training data')\n",
    "\n",
    "test_cm = confusion_matrix(test_y, (neural_network.predict(test_bow_matrix) > 0.50).ravel() * 1)\n",
    "sn.heatmap(test_cm, annot = True, cmap='Greens', ax = axs[1])\n",
    "\n",
    "axs[1].set_xlabel('Predictions')\n",
    "axs[1].set_ylabel('True Labels')\n",
    "axs[1].set_title('Test data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# take a look at the distribution of non-churners and churners\n",
    "df['LabelNumber'].plot(kind = 'hist')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# we use SMOTENC which is capable for mixed features (numerical and categorical)\n",
    "# synthetic observations for categorical features are chosen by majority categories per feature\n",
    "# see some information here: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC\n",
    "# we need to tell SMOTENC which features are categorical\n",
    "\n",
    "smt = SMOTENC(categorical_features = list(range(14, 37)), sampling_strategy = 1)\n",
    "X_train_sm, y_train_sm = smt.fit_resample(train_bow_matrix, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_1 = 0\n",
    "counter_2 = 0\n",
    "\n",
    "for i in range (1293):\n",
    "    if y_train_sm[i] == 1:\n",
    "        counter_1 = counter_1 + 1\n",
    "    elif y_train_sm[i] == 2:\n",
    "        counter_2 = counter_2 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               449600    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449,701\n",
      "Trainable params: 449,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 10ms/step - loss: -0.3508 - accuracy: 0.4730 - recall_1: 0.9621 - val_loss: -0.8554 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: -2.0929 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2.1371 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -4.4410 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -4.1954 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -8.3830 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -7.6459 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -14.8667 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -13.1487 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -25.0871 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -21.8159 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -41.1856 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -35.4439 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -66.7370 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -57.6165 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -108.9207 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -95.8723 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -182.7608 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -164.4345 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -316.6328 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -290.2750 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -564.4446 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -526.7991 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -1032.8066 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -978.7742 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -1930.6979 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1853.7585 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -3670.2712 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -3542.8022 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -7033.9653 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -6827.7964 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -13575.1064 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -13260.0205 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -26372.6035 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -25736.7148 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -51242.2188 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -49982.5156 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -99531.2031 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -98178.2188 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -195317.9531 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -191020.9688 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -380152.8125 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -371032.5938 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -738974.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -721301.5625 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -1436687.8750 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1406111.6250 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -2801149.7500 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2741199.2500 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -5459099.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -5328322.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -10618663.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -10405117.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -20734080.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -20339508.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -40504880.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -39467444.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -78627952.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -76980680.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -153341136.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -150147664.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -299157184.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -293178848.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -583919104.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -569827072.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -1134987648.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1111241216.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -2212963840.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2165485568.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -4312598016.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -4220545536.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -8409015296.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -8191178240.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -16322108416.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -15969548288.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -31823192064.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -31193505792.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -62127345664.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -60940734464.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -121395527680.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -118624223232.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -236296060928.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -230632521728.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -459350114304.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -450195456000.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -896594018304.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -877655359488.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -1746568871936.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1709828603904.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -3405147799552.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -3338123608064.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -6649499090944.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -6474221748224.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -12899749724160.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -12681444589568.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -25255556939776.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -24618834329600.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -49038632157184.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -48358286688256.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -96229480464384.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -94031799386112.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -187169322827776.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -183438069989376.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -365157314199552.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -357621257207808.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -711884051316736.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -695754972725248.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -1385259291639808.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1360544036552704.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -2709178934099968.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2643223537254400.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -5262987963138048.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -5148694588424192.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -10249820266561536.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -10050905298698240.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -20005788013559808.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -19478202820853760.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -38781750796615680.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -37845812998307840.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -75395771469398016.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -73397142797942784.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -146229600475676672.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -142113535747424256.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -283185902702821376.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -277809720339726336.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -553221818136133632.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -541162512041639936.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -1078012533320712192.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1055639120962912256.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -2103558708226162688.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2051476354246901760.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -4088522717890871296.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -3995897934221672448.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -7962093661330604032.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -7751066593634811904.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -15449939370299097088.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -15147341675707236352.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -30192120906775527424.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -29706398451065946112.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -59181644373601288192.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -57804237778974670848.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -115117556810286891008.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -112867630564415373312.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -224849248270889779200.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -220433169769090252800.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -438902207150693548032.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -431004828544750583808.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -858061407591180795904.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -839832102936980226048.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -1671411359556804018176.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1634813842347396169728.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: -3254518670894917746688.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -3192795712101898256384.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -6356983996420785700864.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -6205149638583616798720.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -12357584643528861941760.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -12075785407645035266048.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -24046314936598980984832.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -23554373238502419595264.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: -46911119518156567085056.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -45675475895594178838528.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -90987394207669247016960.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -88495147209878688235520.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -176347252450562907570176.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -173007815312469175304192.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: -344748533862578406817792.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -340008080923605241692160.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -676935411471712912408576.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -662026839380453698306048.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -1318424827745040617963520.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1288385890288073447571456.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -2565711228121701108678656.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -2498630219758408627650560.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -4978083896130691569549312.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -4916351290627270251642880.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -9786925832914125644103680.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -9604323242710731702927360.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -19124269925106811309916160.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -18815824223293323111038976.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -37473836551036061008003072.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -36671749060281077566799872.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -73043922996805112015355904.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -71700003904059076341923840.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: -142769258288005801985441792.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -139819762261200197503680512.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 10ms/step - loss: -278350023324671802511196160.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -270962415917800380151365632.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -539707902132822346389520384.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -527517076163806209851260928.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: -1050996086262901104015572992.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1029205832932343548750069760.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -2050075213282896276933836800.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -1995727711040838375315603456.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: -3977058697562838278491602944.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -3888036481550547058509742080.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: -7746110138063096576844234752.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -7571030171598135556663410688.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: -15088878232457813886341480448.0000 - accuracy: 0.5000 - recall_1: 1.0000 - val_loss: -14786161554398041736619229184.0000 - val_accuracy: 0.6921 - val_recall_1: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient train-data: nan\n",
      "Correlation coefficient test-data: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ts23\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\ts23\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "nn_bow_new = build_nn(X_train_sm, y_train_sm, test_bow_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "neural_network = nn_bow_new\n",
    "\n",
    "# let us take a look at the confusion matrix, remember predictions are 1 if the predicted proability for class 1 is higher than 0.5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "train_cm = confusion_matrix(train_y, (neural_network.predict(train_bow_matrix) > 0.50).ravel() * 1)\n",
    "sn.heatmap(train_cm, annot = True, cmap='Greens', ax = axs[0])\n",
    "\n",
    "axs[0].set_xlabel('Predictions')\n",
    "axs[0].set_ylabel('True Labels')\n",
    "axs[0].set_title('Training data')\n",
    "\n",
    "test_cm = confusion_matrix(test_y, (neural_network.predict(test_bow_matrix) > 0.50).ravel() * 1)\n",
    "sn.heatmap(test_cm, annot = True, cmap='Greens', ax = axs[1])\n",
    "\n",
    "axs[1].set_xlabel('Predictions')\n",
    "axs[1].set_ylabel('True Labels')\n",
    "axs[1].set_title('Test data')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d39680e86271bf209db9aab97c2f2e95b8272895522c86f00c9979eddd8c4165"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
